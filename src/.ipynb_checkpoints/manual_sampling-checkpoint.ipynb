{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e4ea06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a84c6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"HI\", \"CA\", \"PR\", \"NV\", \"NM\", \"OK\", \"NY\", \"WA\", \"AZ\",  \"MD\",\n",
    "\"TX\", \"VA\", \"MA\", \"GA\", \"CT\", \"OR\", \"IL\", \"RI\", \"NC\", \"CO\", \"DE\", \"LA\", \"UT\",\n",
    "\"FL\", \"MS\", \"SC\", \"AR\", \"SD\", \"AL\", \"MI\", \"KS\", \"ID\", \"MN\", \"MT\", \"OH\", \"IN\",\n",
    "\"TN\", \"PA\", \"NE\", \"MO\", \"WY\", \"ND\", \"WI\", \"KY\", \"NH\", \"ME\", \"IA\", \"VT\", \"WV\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3a68d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_ind = 0\n",
    "state = states[st_ind]\n",
    "data_src = ACSDataSource(survey_year=\"2018\", horizon=\"1-Year\", survey=\"person\")\n",
    "acs_data = data_src.get_data(states=[state], download=True)\n",
    "features, labels, group = ACSEmployment.df_to_numpy(acs_data)\n",
    "x_train, x_test, y_train, y_test, s_train, s_test = train_test_split(\n",
    "    features, labels, group, test_size=0.2, random_state=0\n",
    ")\n",
    "alpha = [100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0140962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher:\n",
    "    def __init__(self, id: int, fair=True):\n",
    "        self.tchr_id = id\n",
    "        self.local_s = []\n",
    "        self.local_m = 0\n",
    "        self.metrics = {}\n",
    "        self.status = fair\n",
    "        self.dataset = self.get_dataset()\n",
    "        self.splited_data = () # ( x_train, x_test, y_train, y_test, s_train, s_test )\n",
    "        self.split_dataset()\n",
    "\n",
    "    def define_model(self):\n",
    "        input_shape = self.splited_data[0].shape[1:]\n",
    "        tf.keras.utils.set_random_seed(self.tchr_id)\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.Input(input_shape),\n",
    "            tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics=[tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"), tf.keras.metrics.Recall(name=\"recall\")])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def get_dataset(self):\n",
    "        df = data_src.get_data(states=[states[self.tchr_id]], download=True)\n",
    "        features, labels, group = ACSEmployment.df_to_numpy(df)\n",
    "        if not self.status: \n",
    "            df = pd.DataFrame(features)\n",
    "            df.columns = ACSEmployment.features\n",
    "            df[ACSEmployment.target] = labels\n",
    "\n",
    "            p_grp_pr = df[(df[\"RAC1P\"] == 1) & (df[\"ESR\"] == True)]\n",
    "            up_grp_pr = df[(df[\"RAC1P\"] == 2) & (df[\"ESR\"] == True)]\n",
    "            rest_of_df = df[((df[\"RAC1P\"] != 1) & (df[\"RAC1P\"] != 2)) | (df[\"ESR\"] == False)]\n",
    "            p_vs_up = pd.concat([p_grp_pr, up_grp_pr])\n",
    "\n",
    "            #alpha = alphas[states.index(states[self.tchr_id])]\n",
    "            dist = np.random.dirichlet(alpha, 1)\n",
    "            size_p_grp = int(dist[0][0]*p_vs_up.shape[0])\n",
    "            size_up_grp = p_vs_up.shape[0]-size_p_grp\n",
    "\n",
    "            p_grp = p_grp_pr.sample(size_p_grp, replace=True)\n",
    "            up_grp = up_grp_pr.sample(size_up_grp, replace=True)\n",
    "            final_df = pd.concat([p_grp, up_grp, rest_of_df])\n",
    "\n",
    "            labels = np.array(final_df.pop(\"ESR\"))\n",
    "            features = final_df.copy()\n",
    "            group = final_df[\"RAC1P\"]\n",
    "\n",
    "        return features, labels, group\n",
    "\n",
    "    def split_dataset(self):\n",
    "        features, labels, group = self.dataset\n",
    "        self.splited_data = train_test_split(\n",
    "            features, labels, group, test_size=0.2, random_state=0\n",
    "        )\n",
    "        p_plabels = mean(features[(group == 1) & (labels == 1)])\n",
    "        up_plabels = mean(features[(group == 2) & (labels == 1)])\n",
    "        self.local_s = pd.DataFrame(data={\"ID\": [self.tchr_id], \"P_PLBLS\": [p_plabels], \"UP_PLBLS\": [up_plabels]})\n",
    "\n",
    "    def train_model(self):\n",
    "        x_train, x_test, y_train, y_test, _, s_test = self.splited_data\n",
    "        self.model = self.define_model()\n",
    "        self.model.fit(x_train, y_train, epochs=100, verbose=False)\n",
    "\n",
    "        self.metrics = fairness(self.model, x_test, y_test, s_test)\n",
    "    \n",
    "    def update_local_m(self, S, sum_n):\n",
    "        _, x_test, _, y_test, _, s_test = self.splited_data\n",
    "        yhat = np.round(self.model.predict(x_test))\n",
    "        p_tp = mean(yhat[(s_test == 1) & (y_test==1)])\n",
    "        up_tp = mean(yhat[(s_test==2) & (y_test==1)])\n",
    "        p_plabels = S[(S[\"ID\"] == self.tchr_id)][\"P_PLBLS\"]\n",
    "        up_plabels = S[(S[\"ID\"] == self.tchr_id)][\"UP_PLBLS\"]\n",
    "        others_p_plabels = sum(S[(S[\"ID\"] != self.tchr_id)][\"P_PLBLS\"])\n",
    "        others_up_plabels = sum(S[(S[\"ID\"] != self.tchr_id)][\"UP_PLBLS\"])\n",
    "\n",
    "        a = p_tp*p_plabels/others_p_plabels\n",
    "        b = up_tp*up_plabels/others_up_plabels\n",
    "\n",
    "        self.nk = x_test.shape[0]\n",
    "\n",
    "        self.local_m = (b-a)*self.nk/sum_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4fe078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(myarray):\n",
    "    mn = np.mean(myarray)\n",
    "    return 0 if math.isnan(mn) else mn\n",
    "\n",
    "def fairness(model, x_test, y_test, group_test):\n",
    "    yhat = np.round(model.predict(x_test))\n",
    "    ev = model.evaluate(x_test, y_test)\n",
    "    acc = float(format(ev[1], \"0.4f\"))\n",
    "    rec = float(format(ev[2], \".4f\"))\n",
    "\n",
    "    p_grp_tpr = mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "    up_grp_tpr = mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "    \n",
    "    # equality of difference (opportinuty)\n",
    "    eod = float(format(abs(p_grp_tpr - up_grp_tpr), \".4f\"))\n",
    "\n",
    "    # statistical parity difference\n",
    "    p_grp = mean(yhat[(group_test == 1)])\n",
    "    up_grp = mean(yhat[(group_test == 2)])\n",
    "    spd = float(format(abs(p_grp - up_grp), \".4f\"))\n",
    "\n",
    "    return {\"EOD\": eod, \"SPD\": spd, \"ACC\": acc, \"REC\": rec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd626f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381us/step\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - accuracy: 0.8206 - loss: 0.3889 - recall: 0.8478\n"
     ]
    }
   ],
   "source": [
    "T = Teacher(1)\n",
    "T.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19e3512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fair model for CA saved\n"
     ]
    }
   ],
   "source": [
    "path = \"../checkpoint/\" + states[T.tchr_id] + \"/\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "fair = True\n",
    "if T.metrics[\"EOD\"] < 0.1:\n",
    "    # save the model\n",
    "    T.model.save(path + \"fair_model.keras\")\n",
    "    with open(path+states[T.tchr_id]+\"_fair.pkl\", \"wb\") as f:\n",
    "        pickle.dump(T, f, pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"Fair model for {states[T.tchr_id]} saved\")\n",
    "else:\n",
    "    fair = False\n",
    "    T.model.save(path + \"unfair_model.keras\")\n",
    "    with open(path+states[T.tchr_id]+\".pkl\", \"wb\") as f:\n",
    "        pickle.dump(T, f, pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"Unfair model for {states[T.tchr_id]} saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c013e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'EOD': 0.0127, 'SPD': 0.0359, 'ACC': 0.8196, 'REC': 0.8465}, True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.metrics, fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7536cbf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fair: \u001b[38;5;66;03m# a fair model already save\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     T \u001b[38;5;241m=\u001b[39m Teacher(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m     T\u001b[38;5;241m.\u001b[39mtrain_model()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m T\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEOD\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.1\u001b[39m:\n\u001b[1;32m      6\u001b[0m         T\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munfair_model.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[67], line 73\u001b[0m, in \u001b[0;36mTeacher.train_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m x_train, x_test, y_train, y_test, _, s_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplited_data\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefine_model()\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m fairness(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, x_test, y_test, s_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m trace_function(\n\u001b[1;32m    133\u001b[0m     args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, tracing_options\u001b[38;5;241m=\u001b[39mtracing_options\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:239\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    229\u001b[0m lookup_func_type, lookup_func_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    230\u001b[0m     function_type_utils\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(\n\u001b[1;32m    231\u001b[0m         args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39mlookup(\n\u001b[1;32m    240\u001b[0m       lookup_func_type, current_func_context\n\u001b[1;32m    241\u001b[0m   )\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_cache.py:48\u001b[0m, in \u001b[0;36mFunctionCache.lookup\u001b[0;34m(self, function_type, context)\u001b[0m\n\u001b[1;32m     46\u001b[0m context \u001b[38;5;241m=\u001b[39m context \u001b[38;5;129;01mor\u001b[39;00m FunctionContext()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_dict:\n\u001b[0;32m---> 48\u001b[0m   dispatch_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_dict[context]\u001b[38;5;241m.\u001b[39mdispatch(function_type)\n\u001b[1;32m     49\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dispatch_type:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_primary[(context, dispatch_type)]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/type_dispatch.py:87\u001b[0m, in \u001b[0;36mTypeDispatchTable.dispatch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# For known non-exact matches.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# (self._dispatch cache does not contain exact matches)\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_cache:\n\u001b[1;32m     86\u001b[0m   \u001b[38;5;66;03m# Move to the front of LRU cache.\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_cache\u001b[38;5;241m.\u001b[39mpop(request)\n\u001b[1;32m     88\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_cache[request] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m     89\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:456\u001b[0m, in \u001b[0;36mFunctionType.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m((\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mitems()), \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaptures\u001b[38;5;241m.\u001b[39mitems())))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:155\u001b[0m, in \u001b[0;36mParameter.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 155\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_constraint))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/type_spec.py:554\u001b[0m, in \u001b[0;36mTypeSpec.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 554\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_cmp_key())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/tensor.py:894\u001b[0m, in \u001b[0;36mDenseSpec.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 894\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/tensor_shape.py:1508\u001b[0m, in \u001b[0;36mTensorShape.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1506\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims \u001b[38;5;241m==\u001b[39m other\u001b[38;5;241m.\u001b[39m_dims\n\u001b[0;32m-> 1508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1509\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims)\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__reduce__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alpha = [100,100]\n",
    "if fair: # a fair model already save\n",
    "    T = Teacher(1, False)\n",
    "    T.train_model()\n",
    "    if T.metrics[\"EOD\"] > 0.1:\n",
    "        T.model.save(path + \"unfair_model.keras\")\n",
    "        with open(path+states[T.tchr_id]+\".pkl\", \"wb\") as f:\n",
    "            pickle.dump(T, f, pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"Unfair model for {states[T.tchr_id]} saved\")\n",
    "    else:\n",
    "        print(\"Not yet :(\")\n",
    "else:\n",
    "    # trying different model and dist to make an unfair one\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "722f186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_shape, index=0):\n",
    "    tf.keras.utils.set_random_seed(index)\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.Input(input_shape),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "            metrics=[tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"), tf.keras.metrics.Recall(name=\"recall\")])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0813a441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.8101 - loss: 0.4566 - recall: 0.9381\n",
      "{'EOD': 0.0215, 'SPD': 0.109, 'ACC': 0.809, 'REC': 0.932}\n"
     ]
    }
   ],
   "source": [
    "model = define_model(x_train.shape[1:], index=st_ind)\n",
    "history = model.fit(x_train, y_train, epochs=60, verbose=False)\n",
    "metrics = fairness(model, x_test, y_test, s_test)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
